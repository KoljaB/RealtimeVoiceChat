import asyncio
import logging
import os
import threading
import time
from queue import Queue, Empty
from typing import Callable, Generator, Optional, Tuple

import numpy as np
import torch
from chatterbox.tts import ChatterboxTTS, StreamingMetrics

logger = logging.getLogger(__name__)

# Configuration constants
DEFAULT_CHUNK_SIZE = 25  # Number of speech tokens per chunk
DEFAULT_TEMPERATURE = 0.8
DEFAULT_CFG_WEIGHT = 0.5
DEFAULT_EXAGGERATION = 0.5

class ChatterboxAudioProcessor:
    """
    åŸç”ŸChatterboxéŸ³é¢‘å¤„ç†å™¨
    ç›´æ¥ä½¿ç”¨chatterbox-streamingï¼Œæ— é€‚é…å±‚
    
    è¿™ä¸ªç±»æä¾›äº†å®Œæ•´çš„TTSåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - æ–‡æœ¬åˆ°è¯­éŸ³çš„æµå¼åˆæˆ
    - éŸ³é¢‘å—çš„å¼‚æ­¥å¤„ç†
    - ç”ŸæˆçŠ¶æ€ç®¡ç†
    - èµ„æºæ¸…ç†
    """
    
    def __init__(
        self, 
        device: str = "cuda",
        chunk_size: int = DEFAULT_CHUNK_SIZE,
        temperature: float = DEFAULT_TEMPERATURE,
        cfg_weight: float = DEFAULT_CFG_WEIGHT,
        exaggeration: float = DEFAULT_EXAGGERATION
    ):
        """
        åˆå§‹åŒ–ChatterboxAudioProcessor
        
        Args:
            device: è®¡ç®—è®¾å¤‡ ("cuda", "cpu", "mps")
            chunk_size: æ¯ä¸ªéŸ³é¢‘å—çš„tokenæ•°é‡
            temperature: ç”Ÿæˆæ¸©åº¦ï¼Œæ§åˆ¶éšæœºæ€§
            cfg_weight: åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼æƒé‡
            exaggeration: æƒ…æ„Ÿå¤¸å¼ ç¨‹åº¦
        """
        self.device = device
        self.chunk_size = chunk_size
        self.temperature = temperature
        self.cfg_weight = cfg_weight
        self.exaggeration = exaggeration
        
        # åˆå§‹åŒ–æ¨¡å‹
        logger.info(f"ğŸµ åˆå§‹åŒ–Chatterboxæ¨¡å‹ï¼Œè®¾å¤‡: {device}")
        if device == "cuda" and not torch.cuda.is_available():
            logger.warning("CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
            self.device = "cpu"
            
        self.model = ChatterboxTTS.from_pretrained(device=self.device)
        self.sr = self.model.sr  # é‡‡æ ·ç‡
        
        # çŠ¶æ€ç®¡ç†
        self.is_generating = False
        self.stop_event = threading.Event()
        self.generation_lock = threading.Lock()
        
        # å›è°ƒå‡½æ•°
        self.on_first_audio_chunk_callback: Optional[Callable[[], None]] = None
        
        logger.info(f"ğŸµ Chatterboxæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œé‡‡æ ·ç‡: {self.sr}Hz")
        
    def set_voice_from_audio(
        self, 
        audio_path: str, 
        exaggeration: Optional[float] = None
    ) -> None:
        """
        ä»éŸ³é¢‘æ–‡ä»¶è®¾ç½®è¯­éŸ³é£æ ¼
        
        Args:
            audio_path: å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„
            exaggeration: æƒ…æ„Ÿå¤¸å¼ ç¨‹åº¦ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
        """
        if exaggeration is None:
            exaggeration = self.exaggeration
            
        logger.info(f"ğŸµ è®¾ç½®è¯­éŸ³é£æ ¼ï¼Œå‚è€ƒéŸ³é¢‘: {audio_path}")
        self.model.prepare_conditionals(audio_path, exaggeration=exaggeration)
        logger.info("ğŸµ è¯­éŸ³é£æ ¼è®¾ç½®å®Œæˆ")
        
    async def synthesize_text(
        self,
        text: str,
        audio_chunks: Queue,
        stop_event: threading.Event,
        generation_string: str = "",
        audio_prompt_path: Optional[str] = None,
        exaggeration: Optional[float] = None,
        cfg_weight: Optional[float] = None,
        temperature: Optional[float] = None,
        chunk_size: Optional[int] = None
    ) -> bool:
        """
        åˆæˆå•ä¸ªæ–‡æœ¬ä¸ºéŸ³é¢‘æµ
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            audio_chunks: éŸ³é¢‘å—è¾“å‡ºé˜Ÿåˆ—
            stop_event: åœæ­¢äº‹ä»¶
            generation_string: ç”Ÿæˆæ ‡è¯†å­—ç¬¦ä¸²ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            audio_prompt_path: å¯é€‰çš„éŸ³é¢‘æç¤ºè·¯å¾„
            exaggeration: æƒ…æ„Ÿå¤¸å¼ ç¨‹åº¦
            cfg_weight: åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼æƒé‡
            temperature: ç”Ÿæˆæ¸©åº¦
            chunk_size: å—å¤§å°
            
        Returns:
            bool: å¦‚æœåˆæˆå®Œæˆè¿”å›Trueï¼Œå¦‚æœè¢«ä¸­æ–­è¿”å›False
        """
        # ä½¿ç”¨æä¾›çš„å‚æ•°æˆ–é»˜è®¤å€¼
        exaggeration = exaggeration or self.exaggeration
        cfg_weight = cfg_weight or self.cfg_weight
        temperature = temperature or self.temperature
        chunk_size = chunk_size or self.chunk_size
        
        logger.info(f"ğŸµ {generation_string} å¼€å§‹æ–‡æœ¬åˆæˆ: {text[:50]}...")
        
        with self.generation_lock:
            if self.is_generating:
                logger.warning(f"ğŸµ {generation_string} å·²æœ‰ç”Ÿæˆä»»åŠ¡åœ¨è¿›è¡Œï¼Œè·³è¿‡")
                return False
            self.is_generating = True
            
        try:
            first_chunk_sent = False
            chunk_count = 0
            
            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥çš„ç”Ÿæˆæ–¹æ³•
            loop = asyncio.get_event_loop()
            
            def generate_audio():
                """åœ¨çº¿ç¨‹ä¸­è¿è¡Œçš„ç”Ÿæˆå‡½æ•°"""
                try:
                    for audio_chunk, metrics in self.model.generate_stream(
                        text=text,
                        audio_prompt_path=audio_prompt_path,
                        exaggeration=exaggeration,
                        cfg_weight=cfg_weight,
                        temperature=temperature,
                        chunk_size=chunk_size,
                        print_metrics=False
                    ):
                        if stop_event.is_set():
                            logger.info(f"ğŸµ {generation_string} ç”Ÿæˆè¢«ä¸­æ–­")
                            return False
                            
                        # è½¬æ¢ä¸ºnumpyæ•°ç»„
                        audio_data = audio_chunk.cpu().numpy().squeeze()
                        
                        # ç¡®ä¿éŸ³é¢‘æ•°æ®åœ¨[-1, 1]èŒƒå›´å†…
                        if audio_data.max() > 1.0 or audio_data.min() < -1.0:
                            audio_data = np.clip(audio_data, -1.0, 1.0)
                        
                        # è½¬æ¢ä¸ºå­—èŠ‚æ ¼å¼
                        audio_bytes = audio_data.tobytes()
                        
                        # æ”¾å…¥é˜Ÿåˆ—
                        try:
                            audio_chunks.put_nowait(audio_bytes)
                            chunk_count += 1
                            
                            # è§¦å‘ç¬¬ä¸€ä¸ªéŸ³é¢‘å—å›è°ƒ
                            if not first_chunk_sent and self.on_first_audio_chunk_callback:
                                logger.info(f"ğŸµ {generation_string} è§¦å‘ç¬¬ä¸€ä¸ªéŸ³é¢‘å—å›è°ƒ")
                                self.on_first_audio_chunk_callback()
                                first_chunk_sent = True
                                
                            logger.debug(f"ğŸµ {generation_string} éŸ³é¢‘å—å·²æ”¾å…¥é˜Ÿåˆ—ï¼Œå¤§å°: {len(audio_bytes)} å­—èŠ‚")
                            
                        except Exception as e:
                            logger.warning(f"ğŸµ {generation_string} éŸ³é¢‘é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒå—: {e}")
                            
                    logger.info(f"ğŸµ {generation_string} æ–‡æœ¬åˆæˆå®Œæˆï¼Œå…±ç”Ÿæˆ{chunk_count}ä¸ªéŸ³é¢‘å—")
                    return True
                    
                except Exception as e:
                    logger.error(f"ğŸµ {generation_string} ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                    import traceback
                    logger.error(traceback.format_exc())
                    return False
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œç”Ÿæˆ
            result = await loop.run_in_executor(None, generate_audio)
            return result
            
        finally:
            self.is_generating = False
            
    async def synthesize_generator(
        self,
        text_generator: Generator[str, None, None],
        audio_chunks: Queue,
        stop_event: threading.Event,
        generation_string: str = "",
        audio_prompt_path: Optional[str] = None,
        exaggeration: Optional[float] = None,
        cfg_weight: Optional[float] = None,
        temperature: Optional[float] = None,
        chunk_size: Optional[int] = None
    ) -> bool:
        """
        ä»æ–‡æœ¬ç”Ÿæˆå™¨åˆæˆéŸ³é¢‘æµ
        
        Args:
            text_generator: æ–‡æœ¬ç”Ÿæˆå™¨
            audio_chunks: éŸ³é¢‘å—è¾“å‡ºé˜Ÿåˆ—
            stop_event: åœæ­¢äº‹ä»¶
            generation_string: ç”Ÿæˆæ ‡è¯†å­—ç¬¦ä¸²ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            audio_prompt_path: å¯é€‰çš„éŸ³é¢‘æç¤ºè·¯å¾„
            exaggeration: æƒ…æ„Ÿå¤¸å¼ ç¨‹åº¦
            cfg_weight: åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼æƒé‡
            temperature: ç”Ÿæˆæ¸©åº¦
            chunk_size: å—å¤§å°
            
        Returns:
            bool: å¦‚æœåˆæˆå®Œæˆè¿”å›Trueï¼Œå¦‚æœè¢«ä¸­æ–­è¿”å›False
        """
        logger.info(f"ğŸµ {generation_string} å¼€å§‹ç”Ÿæˆå™¨åˆæˆ")
        
        # æ”¶é›†æ‰€æœ‰æ–‡æœ¬
        accumulated_text = ""
        try:
            for text_chunk in text_generator:
                if stop_event.is_set():
                    logger.info(f"ğŸµ {generation_string} ç”Ÿæˆå™¨åˆæˆè¢«ä¸­æ–­")
                    return False
                accumulated_text += text_chunk
                
            # å¦‚æœæœ‰ç´¯ç§¯çš„æ–‡æœ¬ï¼Œè¿›è¡Œåˆæˆ
            if accumulated_text.strip():
                return await self.synthesize_text(
                    text=accumulated_text,
                    audio_chunks=audio_chunks,
                    stop_event=stop_event,
                    generation_string=generation_string,
                    audio_prompt_path=audio_prompt_path,
                    exaggeration=exaggeration,
                    cfg_weight=cfg_weight,
                    temperature=temperature,
                    chunk_size=chunk_size
                )
            else:
                logger.warning(f"ğŸµ {generation_string} ç”Ÿæˆå™¨æ²¡æœ‰äº§ç”Ÿæ–‡æœ¬")
                return True
                
        except Exception as e:
            logger.error(f"ğŸµ {generation_string} ç”Ÿæˆå™¨åˆæˆå‡ºé”™: {e}")
            return False
            
    def stop_synthesis(self) -> None:
        """åœæ­¢å½“å‰çš„åˆæˆä»»åŠ¡"""
        logger.info("ğŸµ åœæ­¢éŸ³é¢‘åˆæˆ")
        self.stop_event.set()
        
    def is_synthesizing(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ­£åœ¨åˆæˆ"""
        return self.is_generating
        
    def cleanup_resources(self) -> None:
        """æ¸…ç†èµ„æºï¼Œç‰¹åˆ«æ˜¯GPUå†…å­˜"""
        logger.info("ğŸµ æ¸…ç†Chatterboxèµ„æº")
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            logger.info("ğŸµ å·²æ¸…ç†CUDAç¼“å­˜")
            
    def get_stream_info(self) -> Tuple[str, int, int]:
        """
        è¿”å›éŸ³é¢‘æµçš„æ ¼å¼ã€é€šé“æ•°å’Œé‡‡æ ·ç‡ä¿¡æ¯
        
        Returns:
            tuple: (format, channels, rate) éŸ³é¢‘æ ¼å¼ã€é€šé“æ•°å’Œé‡‡æ ·ç‡
        """
        return "pcm", 1, self.sr


# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™AudioProcessorç±»å
class AudioProcessor(ChatterboxAudioProcessor):
    """
    å‘åå…¼å®¹çš„AudioProcessorç±»
    ç°åœ¨ç›´æ¥ç»§æ‰¿è‡ªChatterboxAudioProcessor
    """
    
    def __init__(self, engine: str = "chatterbox", **kwargs):
        """
        åˆå§‹åŒ–AudioProcessor
        
        Args:
            engine: TTSå¼•æ“åç§°ï¼ˆç°åœ¨åªæ”¯æŒ"chatterbox"ï¼‰
            **kwargs: å…¶ä»–å‚æ•°ä¼ é€’ç»™ChatterboxAudioProcessor
        """
        if engine != "chatterbox":
            logger.warning(f"ä¸æ”¯æŒçš„å¼•æ“: {engine}ï¼Œä½¿ç”¨chatterbox")
            
        super().__init__(**kwargs)
        self.engine_name = "chatterbox"
        
        # ä¸ºäº†å…¼å®¹æ€§ï¼Œæ·»åŠ ä¸€äº›æ—§çš„å±æ€§
        self.audio_chunks = asyncio.Queue()
        self.finished_event = threading.Event()
        
        # è®¾ç½®é»˜è®¤è¯­éŸ³ï¼ˆå¦‚æœå­˜åœ¨å‚è€ƒéŸ³é¢‘ï¼‰
        reference_audio_path = "reference_audio.wav"
        if os.path.exists(reference_audio_path):
            try:
                self.set_voice_from_audio(reference_audio_path)
                logger.info(f"ğŸµ ä½¿ç”¨å‚è€ƒéŸ³é¢‘è®¾ç½®é»˜è®¤è¯­éŸ³: {reference_audio_path}")
            except Exception as e:
                logger.warning(f"ğŸµ æ— æ³•åŠ è½½å‚è€ƒéŸ³é¢‘: {e}")
                
    def on_audio_stream_stop(self) -> None:
        """
        å…¼å®¹æ€§æ–¹æ³•ï¼šéŸ³é¢‘æµåœæ­¢å›è°ƒ
        """
        logger.info("ğŸµ éŸ³é¢‘æµåœæ­¢")
        self.finished_event.set()
        
    def synthesize(
        self,
        text: str,
        audio_chunks: Queue,
        stop_event: threading.Event,
        generation_string: str = "",
    ) -> bool:
        """
        å…¼å®¹æ€§æ–¹æ³•ï¼šåŒæ­¥åˆæˆæ–‡æœ¬
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            audio_chunks: éŸ³é¢‘å—è¾“å‡ºé˜Ÿåˆ—
            stop_event: åœæ­¢äº‹ä»¶
            generation_string: ç”Ÿæˆæ ‡è¯†å­—ç¬¦ä¸²
            
        Returns:
            bool: åˆæˆæ˜¯å¦æˆåŠŸå®Œæˆ
        """
        # åˆ›å»ºäº‹ä»¶å¾ªç¯æ¥è¿è¡Œå¼‚æ­¥æ–¹æ³•
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(
                self.synthesize_text(text, audio_chunks, stop_event, generation_string)
            )
            return result
        except Exception as e:
            logger.error(f"ğŸµ åŒæ­¥åˆæˆå‡ºé”™: {e}")
            return False
        finally:
            loop.close()
            
    def synthesize_generator(
        self,
        generator: Generator[str, None, None],
        audio_chunks: Queue,
        stop_event: threading.Event,
        generation_string: str = "",
    ) -> bool:
        """
        å…¼å®¹æ€§æ–¹æ³•ï¼šåŒæ­¥åˆæˆç”Ÿæˆå™¨
        
        Args:
            generator: æ–‡æœ¬ç”Ÿæˆå™¨
            audio_chunks: éŸ³é¢‘å—è¾“å‡ºé˜Ÿåˆ—
            stop_event: åœæ­¢äº‹ä»¶
            generation_string: ç”Ÿæˆæ ‡è¯†å­—ç¬¦ä¸²
            
        Returns:
            bool: åˆæˆæ˜¯å¦æˆåŠŸå®Œæˆ
        """
        # åˆ›å»ºäº‹ä»¶å¾ªç¯æ¥è¿è¡Œå¼‚æ­¥æ–¹æ³•
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(
                super().synthesize_generator(generator, audio_chunks, stop_event, generation_string)
            )
            return result
        except Exception as e:
            logger.error(f"ğŸµ åŒæ­¥ç”Ÿæˆå™¨åˆæˆå‡ºé”™: {e}")
            return False
        finally:
            loop.close()